<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
    <meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="stylesheet" href="files/jemdoc.css" type="text/css" />
    <title>Yuting He-何宇霆个人主页</title>
</head>
<body>
    <div class="menu">
        <a href="#home"><b>Home</b></a>
        <a href="#awards"><b>Awards</b></a>
        <a href="#publications"><b>Research</b></a>
        <a href="#services"><b>Services</b></a>
    </div>

    <a id="home" class="anchor"></a>
    <div id="container">
        <div class="container">
            <div id="toptitle">
                <h1>Yuting He&nbsp;&nbsp;何宇霆</h1>
            </div>

            <table class="imgtable" width="100%">
                <tr>
                    <td align="right">
                        <p>
                            <font color="#424949" size="4"><b>Research Associate</b></font><br/><br/>
                            Rm 517A, Wickenden Bldg,<br/>
                            Case Western Reserve University<br/>
                            Cleveland, OH 44106<br/><br/>
                            Email: 
                            <font face="courier new, monospace">yuting</font>&nbsp;[DOT] 
                            <font face="courier new, monospace">he4</font>&nbsp;[AT] 
                            <font face="courier new, monospace">case</font>&nbsp;[DOT] 
                            <font face="courier new, monospace">edu</font><br/><br/>
                            <a href="https://scholar.google.com/citations?hl=zh-CN&user=WYzBMTUAAAAJ">
                                <img src="./files/google_scholar.png" height="20px" style="margin-bottom:-3px">&nbsp;Google Scholar
                            </a>&nbsp;
                            <a href="https://github.com/YutingHe-list">
                                <img src="./files/github_s.jpg" height="20px" style="margin-bottom:-3px">&nbsp;Github
                            </a>&nbsp;
                            <a href="https://www.researchgate.net/profile/Yuting-He-17?ev=hdr_xprf">
                                <img src="./files/rg.png" height="20px" style="margin-bottom:-3px">&nbsp;ResearchGate
                            </a>&nbsp;
                        </p>
                        <p style="color:red; font-family:Impact, Verdana, sans-serif; font-weight:bold; margin-top:10px;">
                            If you are interested in medical image analysis or foundational models, please feel free to contact me.
                        </p>
                    </td>
                    <td align="left" width="250px">
                        <img src="./files/yutinghe_.jpg" alt="" height="250px" />
                    </td>
                </tr>
            </table>

            <h2>Biography</h2>
            <p>
                I am currently a Research Associate in the department of biomedical engineering, Case Western Reserve University, 
                working with <a href="https://case.edu/engineering/about/faculty-and-staff-directory/shuo-li">Shuo Li</a>. 
                Drawing upon biomedical informatics, computer vision, and deep learning, my research focuses on developing novel methodologies 
                to learn more efficient extraction of knowledge in medical information for computer-aided diagnosis, surgery, and medical imaging. 
                I have published more than 20 peer-reviewed journal/conference articles, including RBME, CVPR, ECCV, TNNLS, MedIA, NC, TIP, J-BHI, IJCAI, MICCAI, IPMI, etc. 
                I was the organizer of the MICCAI-KiPA22 challenge, and provided professional service for J-BHI, TMI, CVPR, ICCV, MICCAI, AAAI, and NeurIPS.
            </p>

            <h2>News</h2>
            <div style="height: 240px; overflow: auto;">
                <ul>
                    <li>[2025.07] 1 paper named <a href="https://ieeexplore.ieee.org/abstract/document/11079704">Adaptation follow human attention: Gaze-assisted medical segment anything model</a> has been accepted by IEEE TCSVT (IF: 11.1)</li>
                    <li>[2025.07] 1 paper has been accepted by IEEE TMI (IF: 9.8)</li>
                    <li>[2025.06] 1 paper has been accepted by ICCV 2025</li>
                    <li>[2025.05] 1 paper has been accepted by ICML 2025</li>
                    <li>[2025.02] 1 paper about <a href="https://arxiv.org/abs/2502.05282">Homeomorphism and Medical Image Representation Learning</a> has been accepted by T-PAMI (IF: 20.8)</li>
                    <li>[2024.11] Our survey on <a href="https://arxiv.org/abs/2404.03264">healthcare foundation model</a> has been accepted by IEEE RBME (IF: 17.2)</li>
                    <li>[2024.10] An imaging foundation model, <a href="https://arxiv.org/abs/2410.01591">TAMP</a>, has been released. It can achieve universal enhancement for any non-ideal measurement CT images.</li>
                    <li>[2024.04] A survey about <a href="https://arxiv.org/abs/2404.03264">healthcare foundation models</a> has been released. This survey is "Foundation Model for Advancing Healthcare: Challenges, Opportunities and Future Directions"</li>
                    <li>[2023.12] I have graduated from Southeast University! My PhD thesis is "<a href="./files/PhD_thesis_YutingHe.pdf">Data-Efficient Learning Algorithm in Medical Image Segmentation</a>" (in Chinese)</li>
                    <li>[2023.12] 1 paper has been accepted by J-BHI 2023</li>
                    <li>[2023.11] I achieved the Bao Gang Outstanding Student Award which is one of the top educational scholarships in China (Only 500 students in China each year)</li>
                    <li>[2023.11] Our paper "Segment Anything in Medical Images" has been formally accepted by Nature Communications (Impact Factor: 17.0) <a href="https://github.com/bowang-lab/MedSAM">[code]</a></li>
                    <li>[2023.09] 1 paper has been accepted by ICCV 2023</li>
                    <li>[2023.06] 2 papers have been accepted by MICCAI 2023</li>
                    <li>[2023.02] 1 paper has been accepted by CVPR 2023</li>
                    <li>[2023.02] 1 paper has been accepted by JBHI</li>
                    <li>[2023.02] 1 paper has been accepted by KBS</li>
                    <li>[2022.08] 1 paper has been accepted by TNNLS</li>
                    <li>[2022.06] <a href="https://kipa22.grand-challenge.org/">MICCAI 2022 KiPA</a> challenge is in full swing</li>
                    <li>[2022.06] 4 papers are accepted by MICCAI 2022</li>
                    <li>[2022.05] 1 paper has been accepted by IJCAI</li>
                    <li>[2021.10] 1 paper has been accepted by TIP</li>
                </ul>
            </div>

            <a id="awards" class="anchor"></a>
            <h2>Awards and Honors</h2>
            <ul>
                <li>2023, Bao Gang Outstanding Student Award (宝钢优秀学生奖, <span style="color:blue">500 students in China each year</span>)</li>
                <li>2021, 2023, National Scholarship</li>
                <li>2023, Merit student of Jiangsu Province</li>
                <li>2022, Southeast University Good Youth Award (东大好青年, <span style="color:blue">10 students in SEU each year</span>)</li>
                <li>2022, Southeast University Graduate Student of the Year (正·青年, <span style="color:blue">10 graduated students in SEU each year</span>)</li>
                <li>2019-2021, Merit student of Southeast University</li>
                <li>2020, Southeast University Doctoral Freshman Award</li>
            </ul>

            <a id="publications" class="anchor"></a>
                <h2>Selected Publications [<a href="https://scholar.google.com/citations?hl=zh-CN&user=WYzBMTUAAAAJ" target="_blank">Google Scholar</a>]</h2>
                
                <h3>☆ Foundation and Pre-training Models for Biomedical Data</h3>
                <table class="imgtable" width="100%" bgcolor="#F0F0F0">
                    <tr>
                        <td>
                            <p class="pub_title">Vector Contrastive Learning For Pixel-Wise Pretraining In Medical Vision.</p>
                            <p class="pub_author">
                                <u><b>Yuting He</b></u>, Shuo Li<br/>
                                <i>IEEE/CVF International Conference on Computer Vision</i><br/>
                                <font color="#922B21"><b>ICCV 2025</b></font> | 
                                <a href="https://arxiv.org/abs/2506.20850">Paper</a> | 
                                <a href="https://github.com/YutingHe-list/COVER">Code</a> | 
                                <a href="./files/slide_COVER.pdf">Slide</a> | 
                                <a href="https://zhuanlan.zhihu.com/p/1922109536103302891">中文解读</a>
                            </p>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <p class="pub_title">Adaptation follow human attention: Gaze-assisted medical segment anything model.</p>
                            <p class="pub_author">
                                Rongjun Ge, Ruiyi Li, Chong Wang, Yuxin Liu, Heng Zhu, Jean-Louis Coatrieux, Daoqiang Zhang, Jian Lu, Yang Chen, Shuo Li, 
                                <u><b>Yuting He</b></u><br/>
                                <i>IEEE Transactions on Circuits and Systems for Video Technology</i><br/>
                                <font color="#922B21"><b>IEEE T-CSVT 2025</b></font> | 
                                <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=76">Paper</a> | 
                                <a href="https://github.com/Ruiz1026/GAM">Code</a>
                            </p>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <p class="pub_title">Homeomorphism Prior for False Positive and Negative Problem in Medical Image Dense Contrastive Representation Learning.</p>
                            <p class="pub_author">
                                <u><b>Yuting He</b></u>, Boyu Wang, Rongjun Ge, Yang Chen, Guanyu Yang, Shuo Li<br/>
                                <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i><br/>
                                <font color="#922B21"><b>IEEE T-PAMI 2025</b></font> | 
                                <a href="https://arxiv.org/abs/2502.05282">Paper</a> | 
                                <a href="https://github.com/YutingHe-list/GEMINI">Code</a> | 
                                <a href="https://zhuanlan.zhihu.com/p/29316280297">中文解读</a>
                            </p>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <p class="pub_title">Imaging foundation model for universal enhancement of non-ideal measurement CT.</p>
                            <p class="pub_author">
                                Yuxin Liu, Rongjun Ge, <u><b>Yuting He* (Corresponding author)</b></u>, Zhan Wu, Chenyu You, Shuo Li, Yang Chen*<br/>
                                <i>Preprint</i><br/>
                                <font><b>Preprint</b></font> | 
                                <a href="https://arxiv.org/abs/2410.01591">Paper</a> | 
                                <a href="https://github.com/YutingHe-list/TAMP">Code</a> | 
                                <a href="./files/bib_TAMP.txt">Bibtex</a> | 
                                <a href="https://huggingface.co/datasets/YutingHe-list/SimNICT">Dataset</a> | 
                                <a href="https://github.com/YutingHe-list/TAMP/blob/main/document/Model_zoo.md">Model zoo</a> | 
                                <a href="https://zhuanlan.zhihu.com/p/863644551">中文解读</a>
                            </p>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <p class="pub_title">Foundation Model for Advancing Healthcare: Challenges, Opportunities and Future Directions.</p>
                            <p class="pub_author">
                                <u><b>Yuting He</b></u>, Fuxiang Huang, Xinrui Jiang, Yuxiang Nie, Minghao Wang, Jiguang Wang, Hao Chen.<br/>
                                <i>IEEE Reviews in Biomedical Engineering</i><br/>
                                <font color="#922B21"><b>IEEE R-BME 2024</b></font> | 
                                <a href="https://arxiv.org/abs/2404.03264">Paper</a> | 
                                <a href="https://github.com/YutingHe-list/Awesome-Foundation-Models-for-Advancing-Healthcare">Awesome repository</a> | 
                                <a href="./files/bib_HFM.txt">Bibtex</a> | 
                                <a href="https://github.com/YutingHe-list/Awesome-Foundation-Models-for-Advancing-Healthcare/blob/main/files/HFM_Chinese.pdf">中译版</a>
                            </p>
                        </td>
                    </tr>
                </table>
                
                <h3>☆ Representation- and Annotation-Efficient Biomedical Image Analysis</h3>
                <table class="imgtable" width="100%" bgcolor="#F0F0F0">
                    <tr>
                        <td>
                            <p class="pub_title">Learning Better Registration to Learn Better Few-Shot Medical Image Segmentation: Authenticity, Diversity, and Robustness.</p>
                            <p class="pub_author">
                                <u><b>Yuting He</b></u>, Rongjun Ge, Xiaoming Qi, Yang Chen, Jiasong Wu, Jean-Louis Coatrieux, Guanyu Yang, Shuo Li.<br/>
                                <i>IEEE Transactions on Neural Networks and Learning Systems</i><br/>
                                <font color="#922B21"><b>IEEE T-NNLS 2022</b></font> | 
                                <a href="https://ieeexplore.ieee.org/document/9842340">Paper</a> | 
                                <a href="https://github.com/YutingHe-list/BRBS">Code</a> | 
                                <a href="./files/slide_RS.pdf">Slide</a> | 
                                <a href="./files/bib_BRBS.txt">Bibtex</a> | 
                                <a href="./files/paper_Chinese_BRBS.pdf">中译版</a> | 
                                <a href="https://zhuanlan.zhihu.com/p/558337633">中文解读</a>
                            </p>
                        </td>
                    </tr>
                </table>
                
                <h3>☆ AI-assisted Surgery/Diagnosis/Prognosis</h3>
                <table class="imgtable" width="100%" bgcolor="#F0F0F0">
                    <tr>
                        <td>
                            <p class="pub_title">Meta grayscale adaptive network for 3D integrated renal structures segmentation.</p>
                            <p class="pub_author">
                                <u><b>Yuting He</b></u>, Guanyu Yang, Jian Yang, Rongjun Ge, Youyong Kong, Xiaomei Zhu, Shaobo Zhang, Pengfei Shao, Huazhong Shu, Jean-Louis Dillenseger, Jean-Louis Coatrieux, Shuo Li.<br/>
                                <i>Medical Image Analysis</i><br/>
                                <font color="#922B21"><b>MedIA 2021</b></font> | 
                                <a href="https://www.sciencedirect.com/science/article/pii/S1361841521001018?via%3Dihub">Paper</a> | 
                                <a href="https://kipa22.grand-challenge.org/">Data (KiPA22 Challenge)</a> | 
                                <a href="./files/bib_MGANet.txt">Bibtex</a>
                            </p>
                        </td>
                    </tr>
                </table>
                
                <a id="services" class="anchor"></a>
                <h2>Services</h2>
                
                <p>Workshop/Challenge Organizers:</p>
                <ul>
                    <li>Co-organizer of <a href="https://kipa22.grand-challenge.org/">MICCAI-KiPA22</a> challenge.</li>
                </ul>
                
                <p>Conference Reviewer:</p>
                <ul>
                    <li>MICCAI, AAAI, CVPR, ICCV, NeurIPS.</li>
                </ul>
                
                <p>Journal Reviewer:</p>
                <ul>
                    <li>IEEE Transactions on Medical Imaging (TMI)</li>
                    <li>IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</li>
                    <li>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</li>
                    <li>IEEE Journal of Biomedical and Health Informatics (J-BHI)</li>
                    <li>Computerized Medical Imaging and Graphics (CMIG)</li>
                    <li>Machine Intelligence Research (MIR)</li>
                </ul>

        </div>
    </div>
</body>
</html>




