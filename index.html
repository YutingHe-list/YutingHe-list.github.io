<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
    <meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="stylesheet" href="files/jemdoc.css" type="text/css" />
    <title>Yuting He-何宇霆个人主页</title>
</head>
<body>
    <div class="menu">
        <a href="#home"><b>Home</b></a>
        <a href="#awards"><b>Awards</b></a>
        <a href="#publications"><b>Research</b></a>
        <a href="#services"><b>Services</b></a>
    </div>

    <a id="home" class="anchor"></a>
    <div id="container">
        <div class="container">
            <div id="toptitle">
                <h1>Yuting He&nbsp;&nbsp;何宇霆</h1>
            </div>

            <table class="imgtable" width="100%">
                <tr>
                    <td align="right">
                        <p>
                            <font color="#424949" size="4"><b>Research Associate</b></font><br/><br/>
                            Rm 517A, Wickenden Bldg,<br/>
                            Case Western Reserve University<br/>
                            Cleveland, OH 44106<br/><br/>
                            Email: 
                            <font face="courier new, monospace">yuting</font>&nbsp;[DOT] 
                            <font face="courier new, monospace">he4</font>&nbsp;[AT] 
                            <font face="courier new, monospace">case</font>&nbsp;[DOT] 
                            <font face="courier new, monospace">edu</font><br/><br/>
                            <a href="https://scholar.google.com/citations?hl=zh-CN&user=WYzBMTUAAAAJ">
                                <img src="./files/google_scholar.png" height="20px" style="margin-bottom:-3px">&nbsp;Google Scholar
                            </a>&nbsp;
                            <a href="https://github.com/YutingHe-list">
                                <img src="./files/github_s.jpg" height="20px" style="margin-bottom:-3px">&nbsp;Github
                            </a>&nbsp;
                            <a href="https://www.researchgate.net/profile/Yuting-He-17?ev=hdr_xprf">
                                <img src="./files/rg.png" height="20px" style="margin-bottom:-3px">&nbsp;ResearchGate
                            </a>&nbsp;
                        </p>
                        <p style='color: #d9822b; font-family: "Oswald", "Arial Black", sans-serif; margin-top: 10px;'>
                            If you’re interested in medical image analysis or foundational models, I’d be glad to share insights, provide guidance, or explore research opportunities together. Don’t hesitate to get in touch.
                        </p>

                    </td>
                    <td align="left" width="250px">
                        <img src="./files/yutinghe_.jpg" alt="" height="250px" />
                    </td>
                </tr>
            </table>

            <h2>Biography</h2>
            <p>
                I am currently a Research Associate in the department of biomedical engineering, Case Western Reserve University, 
                working with <a href="https://case.edu/engineering/about/faculty-and-staff-directory/shuo-li">Shuo Li</a>. 
                Drawing upon biomedical informatics, computer vision, and deep learning, my research focuses on developing novel methodologies 
                to learn more efficient extraction of knowledge in medical information for computer-aided diagnosis, surgery, and medical imaging. 
                I have published more than 20 peer-reviewed journal/conference articles, including RBME, CVPR, ECCV, TNNLS, MedIA, NC, TIP, J-BHI, IJCAI, MICCAI, IPMI, etc. 
                I was the organizer of the MICCAI-KiPA22 challenge, and provided professional service for J-BHI, TMI, CVPR, ICCV, MICCAI, AAAI, and NeurIPS.
            </p>

            <h2>News</h2>
            <div style="height: 240px; overflow: auto;">
                <ul>
                    <li>[2025.12] Invited to be a guest editor of a special issue (<a href="https://www.mdpi.com/journal/sensors/special_issues/IS6UK91B30">Computer-Aided Medical Imaging Sensors and Their Applications</a>) for the Sensors!</li>
                    <li>[2025.12] 1 paper has been accepted by IEEE TCSVT (IF: 11.1)</li>
                    <li>[2025.07] 1 paper named <a href="https://ieeexplore.ieee.org/abstract/document/11079704">Adaptation follow human attention: Gaze-assisted medical segment anything model</a> has been accepted by IEEE TCSVT (IF: 11.1)</li>
                    <li>[2025.07] 1 paper named <a href="https://ieeexplore.ieee.org/document/11180845">Conditional Virtual Imaging for Few-Shot Vascular Image Segmentation</a> has been accepted by IEEE TMI (IF: 9.8)</li>
                    <li>[2025.06] 1 paper has been accepted by ICCV 2025</li>
                    <li>[2025.05] 1 paper has been accepted by ICML 2025</li>
                    <li>[2025.02] 1 paper about <a href="https://arxiv.org/abs/2502.05282">Homeomorphism and Medical Image Representation Learning</a> has been accepted by T-PAMI (IF: 20.8)</li>
                    <li>[2024.11] Our survey on <a href="https://arxiv.org/abs/2404.03264">healthcare foundation model</a> has been accepted by IEEE RBME (IF: 17.2)</li>
                    <li>[2024.10] An imaging foundation model, <a href="https://arxiv.org/abs/2410.01591">TAMP</a>, has been released. It can achieve universal enhancement for any non-ideal measurement CT images.</li>
                    <li>[2024.04] A survey about <a href="https://arxiv.org/abs/2404.03264">healthcare foundation models</a> has been released. This survey is "Foundation Model for Advancing Healthcare: Challenges, Opportunities and Future Directions"</li>
                    <li>[2023.12] I have graduated from Southeast University! My PhD thesis is "<a href="./files/PhD_thesis_YutingHe.pdf">Data-Efficient Learning Algorithm in Medical Image Segmentation</a>" (in Chinese)</li>
                    <li>[2023.12] 1 paper has been accepted by J-BHI 2023</li>
                    <li>[2023.11] I achieved the Bao Gang Outstanding Student Award which is one of the top educational scholarships in China (Only 500 students in China each year)</li>
                    <li>[2023.11] Our paper "Segment Anything in Medical Images" has been formally accepted by Nature Communications (Impact Factor: 17.0) <a href="https://github.com/bowang-lab/MedSAM">[code]</a></li>
                    <li>[2023.09] 1 paper has been accepted by ICCV 2023</li>
                    <li>[2023.06] 2 papers have been accepted by MICCAI 2023</li>
                    <li>[2023.02] 1 paper has been accepted by CVPR 2023</li>
                    <li>[2023.02] 1 paper has been accepted by JBHI</li>
                    <li>[2023.02] 1 paper has been accepted by KBS</li>
                    <li>[2022.08] 1 paper has been accepted by TNNLS</li>
                    <li>[2022.06] <a href="https://kipa22.grand-challenge.org/">MICCAI 2022 KiPA</a> challenge is in full swing</li>
                    <li>[2022.06] 4 papers are accepted by MICCAI 2022</li>
                    <li>[2022.05] 1 paper has been accepted by IJCAI</li>
                    <li>[2021.10] 1 paper has been accepted by TIP</li>
                </ul>
            </div>

            <a id="awards" class="anchor"></a>
            <h2>Awards and Honors</h2>
            <ul>
                <li>2023, Bao Gang Outstanding Student Award (宝钢优秀学生奖, <span style="color:blue">500 students in China each year</span>)</li>
                <li>2021, 2023, National Scholarship</li>
                <li>2023, Merit student of Jiangsu Province</li>
                <li>2022, Southeast University Good Youth Award (东大好青年, <span style="color:blue">10 students in SEU each year</span>)</li>
                <li>2022, Southeast University Graduate Student of the Year (正·青年, <span style="color:blue">10 graduated students in SEU each year</span>)</li>
                <li>2019-2021, Merit student of Southeast University</li>
                <li>2020, Southeast University Doctoral Freshman Award</li>
            </ul>

            <a id="publications" class="anchor"></a>
                <h2>Selected Publications [<a href="https://scholar.google.com/citations?hl=zh-CN&user=WYzBMTUAAAAJ" target="_blank">Google Scholar</a>]</h2>
                
                <h3>☆ Foundation and Pre-training Models for Biomedical Data</h3>
                <table class="imgtable" width="100%" bgcolor="#F0F0F0">
                    <tr><td>
                        <p class="pub_title">Vector Contrastive Learning For Pixel-Wise Pretraining In Medical Vision.</p>
                        <p class="pub_author"><u><b>Yuting He</b></u>, Shuo Li<br>
                        <i>IEEE/CVF International Conference on Computer Vision</i><br>
                        <font color="#922B21"><b>&nbsp;ICCV 2025&nbsp;</b></font> |<a href="https://arxiv.org/abs/2506.20850">&nbsp;Paper&nbsp;</a> |<a href="https://github.com/YutingHe-list/COVER">&nbsp;Code&nbsp;</a> |<a href="./files/slide_COVER.pdf">&nbsp;Slide&nbsp;</a> |<a href="https://zhuanlan.zhihu.com/p/1922109536103302891">&nbsp;中文解读&nbsp;</a></p>
                        </td></tr>
                        
                        <tr><td>
                        <p class="pub_title">Adaptation follow human attention: Gaze-assisted medical segment anything model.</p>
                        <p class="pub_author">Rongjun Ge, Ruiyi Li, Chong Wang, Yuxin Liu, Heng Zhu, Jean-Louis Coatrieux, Daoqiang Zhang, Jian Lu, Yang Chen, Shuo Li, <u><b>Yuting He</b></u><br>
                        <i>IEEE Transactions on Circuits and Systems for Video Technology</i><br>
                        <font color="#922B21"><b>&nbsp;IEEE T-CSVT 2025&nbsp;</b></font> |<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=76">&nbsp;Paper&nbsp;</a> |<a href="https://github.com/Ruiz1026/GAM">&nbsp;Code&nbsp;</a></p>
                        </td></tr>
                        
                        <tr><td>
                        <p class="pub_title">Homeomorphism Prior for False Positive and Negative Problem in Medical Image Dense Contrastive Representation Learning.</p>
                        <p class="pub_author"><u><b>Yuting He</b></u>, Boyu Wang, Rongjun Ge, Yang Chen, Guanyu Yang, Shuo Li<br>
                        <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i><br>
                        <font color="#922B21"><b>&nbsp;IEEE T-PAMI 2025&nbsp;</b></font> |<a href="https://arxiv.org/abs/2502.05282">&nbsp;Paper&nbsp;</a> |<a href="https://github.com/YutingHe-list/GEMINI">&nbsp;Code&nbsp;</a> |<a href="https://zhuanlan.zhihu.com/p/29316280297">&nbsp;中文解读&nbsp;</a></p>
                        </td></tr>
                        
                        <tr><td>
                        <p class="pub_title">Imaging foundation model for universal enhancement of non-ideal measurement CT.</p>
                        <p class="pub_author">Yuxin Liu, Rongjun Ge, <u><b>Yuting He* (Corresponding author)</b></u>, Zhan Wu, Chenyu You, Shuo Li, Yang Chen*<br>
                        <i>Preprint</i><br>
                        <font><b>&nbsp;Preprint&nbsp;</b></font> |<a href="https://arxiv.org/abs/2410.01591">&nbsp;Paper&nbsp;</a> |<a href="https://github.com/YutingHe-list/TAMP">&nbsp;Code&nbsp;</a> |<a href="./files/bib_TAMP.txt">&nbsp;Bibtex&nbsp;</a> |<a href="https://huggingface.co/datasets/YutingHe-list/SimNICT">&nbsp;Dataset&nbsp;</a> |<a href="https://github.com/YutingHe-list/TAMP/blob/main/document/Model_zoo.md">&nbsp;Model zoo&nbsp;</a> |<a href="https://zhuanlan.zhihu.com/p/863644551">&nbsp;中文解读&nbsp;</a></p>
                        </td></tr>
                        
                        <tr><td>
                        <p class="pub_title">Foundation Model for Advancing Healthcare: Challenges, Opportunities and Future Directions.</p>
                        <p class="pub_author"><u><b>Yuting He</b></u>, Fuxiang Huang, Xinrui Jiang, Yuxiang Nie, Minghao Wang, Jiguang Wang, Hao Chen.<br>
                        <i>IEEE Reviews in Biomedical Engineering</i><br>
                        <font color="#922B21"><b>&nbsp;IEEE R-BME 2024&nbsp;</b></font> |<a href= "https://arxiv.org/abs/2404.03264">&nbsp;Paper&nbsp;</a> |<a href="https://github.com/YutingHe-list/Awesome-Foundation-Models-for-Advancing-Healthcare">&nbsp;Awesome repository&nbsp;</a> |<a href="./files/bib_HFM.txt">&nbsp;Bibtex&nbsp;</a> |<a href="https://github.com/YutingHe-list/Awesome-Foundation-Models-for-Advancing-Healthcare/blob/main/files/HFM_Chinese.pdf">&nbsp;中译版&nbsp;</a></p>
                        </td></tr>
                        
                        <tr><td>
                        <p class="pub_title">Geometric Visual Similarity Learning in 3D Medical Image Self-supervised Pre-training.</p>
                        <p class="pub_author"><u><b>Yuting He</b></u>, Guanyu Yang, Rongjun Ge, Yang Chen, Jean-Louis Coatrieux, Boyu Wang, Shuo Li.<br>
                        <i>IEEE/CVF Conference on Computer Vision and Pattern Recognition</i> (<b>Travel Award</b>)<br>
                        <font color="#922B21"><b>&nbsp;CVPR 2023&nbsp;</b></font> |<a href= "https://arxiv.org/abs/2303.00874">&nbsp;Paper&nbsp;</a> |<a href="https://github.com/YutingHe-list/GVSL">&nbsp;Code&nbsp;</a> |<a href="./files/poster_GVSL.pdf">&nbsp;Poster&nbsp;</a> |<a href="./files/slide_GVSL.pdf">&nbsp;Slide&nbsp;</a> |<a href="https://x-ark.github.io/">&nbsp;Homepage&nbsp;</a> |<a href="./files/bib_GVSL.txt">&nbsp;Bibtex&nbsp;</a> |<a href="./files/paper_Chinese_GVSL.pdf">&nbsp;中译版&nbsp;</a></p>
                        </td></tr>
                        
                        <tr><td>
                        <p class="pub_title">Segment Anything in Medical Images.</p>
                        <p class="pub_author">Jun Ma, <u><b>Yuting He</b></u>, Feifei Li, Lin Han, Chenyu You, Bo Wang.<br>
                        <i>Nature Communication [In Press]</i><br> 
                        <font color="#922B21"><b>&nbsp;Nat. Comm 2023&nbsp;</b></font> |<a href= "https://www.nature.com/articles/s41467-024-44824-z">&nbsp;Paper&nbsp;</a> |<a href="https://github.com/bowang-lab/MedSAM">&nbsp;Code&nbsp;</a></p>
                        </td></tr>
                </table>
                
                <h3>☆ Representation- and Annotation-Efficient Biomedical Image Analysis</h3>
                <table class="imgtable" width="100%" bgcolor="#F0F0F0">
                        <tr><td>
                        <p class="pub_title">Conditional Virtual Imaging for Few-Shot Vascular Image Segmentation.</p>
                        <p class="pub_author">Yanglong He, Rongjun Ge, Hui Tang, Yuxin Liu, Mengqing Su, Jean-Louis Coatrieux, Huazhong Shu, Yang Chen, <u><b>Yuting He</b></u><br>
                        <i>IEEE Transactions on Medical Imaging</i><br>
                        <font color="#922B21"><b>&nbsp;IEEE T-MI 2025&nbsp;</b></font> |<a href= "https://ieeexplore.ieee.org/document/11180845">&nbsp;Paper&nbsp;</a> |<a href="https://github.com/ppIntelligence/CVI">&nbsp;Code&nbsp;</a></p>
                        </td></tr>
                    <tr><td>
                        <p class="pub_title">Learning Better Registration to Learn Better Few-Shot Medical Image Segmentation: Authenticity, Diversity, and Robustness.</p>
                        <p class="pub_author"><u><b>Yuting He</b></u>, Rongjun Ge, Xiaoming Qi, Yang Chen, Jiasong Wu, Jean-Louis Coatrieux, Guanyu Yang, Shuo Li.<br>
                        <i>IEEE transactions on neural networks and learning systems</i><br>
                        <font color="#922B21"><b>&nbsp;IEEE T-NNLS 2022&nbsp;</b></font> |<a href= "https://ieeexplore.ieee.org/document/9842340">&nbsp;Paper&nbsp;</a> |<a href="https://github.com/YutingHe-list/BRBS">&nbsp;Code&nbsp;</a> |<a href="./files/slide_RS.pdf">&nbsp;Slide&nbsp;</a> |<a href="./files/bib_BRBS.txt">&nbsp;Bibtex&nbsp;</a> |<a href="./files/paper_Chinese_BRBS.pdf">&nbsp;中译版&nbsp;</a> |<a href="https://zhuanlan.zhihu.com/p/558337633">&nbsp;中文解读&nbsp;</a></p>
                        </td></tr>
                        
                        <tr><td>
                        <p class="pub_title">Few-shot Learning for Deformable Medical Image Registration with Perception-Correspondence Decoupling and Reverse Teaching.</p>
                        <p class="pub_author"><u><b>Yuting He</b></u>, Tiantian Li, Rongjun Ge, Jian Yang, Youyong Kong, Jian Zhu, Huazhong Shu, Guanyu Yang, Shuo Li.<br>
                        <i>IEEE Journal of Biomedical and Health Informatics</i><br>
                        <font color="#922B21"><b>&nbsp;IEEE J-BHI 2022&nbsp;</b></font> |<a href= "https://ieeexplore.ieee.org/document/9477084">&nbsp;Paper&nbsp;</a> |<a href="https://github.com/YutingHe-list/PC-Reg-RT">&nbsp;Code&nbsp;</a> |<a href="./files/slide_RS.pdf">&nbsp;Slide&nbsp;</a> |<a href="./files/bib_PC_Reg_RT.txt">&nbsp;Bibtex&nbsp;</a> |<a href="./files/paper_Chinese_PC_Reg_RT.pdf">&nbsp;中译版&nbsp;</a></p>
                        </td></tr>
                        
                        <tr><td>
                        <p class="pub_title">Deep complementary joint model for complex scene registration and few-shot segmentation on medical images.</p>
                        <p class="pub_author"><u><b>Yuting He</b></u>, Tiantian Li, Guanyu Yang, Youyong Kong, Yang Chen, Huazhong Shu, Jean-Louis Coatrieux, Jean-Louis Dillenseger, Shuo Li.<br>
                        <i>European Conference on Computer Vision</i><br>
                        <font color="#922B21"><b>&nbsp;ECCV 2020&nbsp;</b></font> |<a href= "https://link.springer.com/chapter/10.1007/978-3-030-58523-5_45">&nbsp;Paper&nbsp;</a> |<a href="#">Code</a> |<a href="./files/slide_DeepRS.pdf">&nbsp;Slide&nbsp;</a> |<a href="./files/bib_DeepRS.txt">&nbsp;Bibtex&nbsp;</a></p>
                        </td></tr>
                        
                        <tr><td>
                        <p class="pub_title">Thin Semantics Enhancement via High-Frequency Priori Rule for Thin Structures Segmentation.</p>
                        <p class="pub_author"><u><b>Yuting He</b></u>, Rongjun Ge, Jiasong Wu, Jean-Louis Coatrieux, Huazhong Shu, Yang Chen, Guanyu Yang, Shuo Li.<br>
                        <i>IEEE International Conference on Data Mining</i><br>
                        <font color="#922B21"><b>&nbsp;ICDM 2021&nbsp;</b></font> |<a href= "https://ieeexplore.ieee.org/abstract/document/9679089">&nbsp;Paper&nbsp;</a> |<a href="#">Code&nbsp;</a> |<a href="./files/bib_HeFiNet.txt">&nbsp;Bibtex&nbsp;</a></p>
                        </td></tr>
                        
                        <tr><td>
                        <p class="pub_title">XMorpher: Full Transformer for Deformable Medical Image Registration via Cross Attention.</p>
                        <p class="pub_author">Jiacheng Shi, <u><b>Yuting He</b></u>, Youyong Kong, Jean-Louis Coatrieux, Huazhong Shu, Guanyu Yang, Shuo Li.<br>
                        <i>International Conference on Medical Image Computing and Computer-Assisted Intervention</i><br>
                        <font color="#922B21"><b>&nbsp;MICCAI 2022&nbsp;</b></font> |<a href= "https://arxiv.org/pdf/2206.07349.pdf">&nbsp;Paper&nbsp;</a> |<a href="https://github.com/Solemoon/XMorpher">&nbsp;Code&nbsp;</a> |<a href="./files/bib_XMorpher.txt">&nbsp;Bibtex&nbsp;</a></p>
                        </td></tr>
                        
                        <tr><td>
                        <p class="pub_title">MNet: Rethinking 2D/3D Networks for Anisotropic Medical Image Segmentation.</p>
                        <p class="pub_author">Zhangfu Dong, <u><b>Yuting He</b></u>, Xiaoming Qi, Yang Chen, Huazhong Shu, Jean-Louis Coatrieux, Guanyu Yang, Shuo Li.<br>
                        <i>International Joint Conference on Artificial Intelligence</i><br>
                        <font color="#922B21"><b>&nbsp;IJCAI 2022&nbsp;</b></font> |<a href= "https://arxiv.org/abs/2205.04846">&nbsp;Paper&nbsp;</a> |<a href="https://github.com/zfdong-code/MNet">&nbsp;Code&nbsp;</a></p>
                        </td></tr>
                </table>
                
                <h3>☆ AI-assisted Surgery/Diagnosis/Prognosis</h3>
                <table class="imgtable" width="100%" bgcolor="#F0F0F0">
                    <tr><td>
                        <p class="pub_title">Meta grayscale adaptive network for 3D integrated renal structures segmentation.</p>
                        <p class="pub_author"><u><b>Yuting He</b></u>, Guanyu Yang, Jian Yang, Rongjun Ge, Youyong Kong, Xiaomei Zhu, Shaobo Zhang, Pengfei Shao, Huazhong Shu, Jean-Louis Dillenseger, Jean-Louis Coatrieux, Shuo Li.<br>
                        <i>Medical Image Analysis</i><br>
                        <font color="#922B21"><b>&nbsp;MedIA 2021&nbsp;</b></font> |<a href= "https://www.sciencedirect.com/science/article/pii/S1361841521001018?via%3Dihub">&nbsp;Paper&nbsp;</a> |<a href= "https://kipa22.grand-challenge.org/">&nbsp;Data (KiPA22 Challenge)&nbsp;</a> |<a href="./files/bib_MGANet.txt">&nbsp;Bibtex&nbsp;</a></p>
                        </td></tr>
                        
                        <tr><td>
                        <p class="pub_title">Dense biased networks with deep priori anatomy and hard region adaptation: Semi-supervised learning for fine renal artery segmentation.</p>
                        <p class="pub_author"><u><b>Yuting He</b></u>, Guanyu Yang*, Jian Yang, Yang Chen, Youyong Kong, Jiasong Wu, Lijun Tang, Xiaomei Zhu, Jean-Louis Dillenseger, Pengfei Shao, Shaobo Zhang, Huazhong Shu, Jean-Louis Coatrieux, Shuo Li.<br>
                        <i>Medical Image Analysis</i><br>
                        <font color="#922B21"><b>&nbsp;MedIA 2020&nbsp;</b></font> |<a href="https://www.sciencedirect.com/science/article/pii/S1361841520300864">&nbsp;Paper&nbsp;</a> |<a href="https://github.com/YutingHe-list/DenseBiasNet-pytorch">&nbsp;Code&nbsp;</a> |<a href="./files/poster_DPA_DenseBiasNet.pdf">&nbsp;Poster&nbsp;</a> |<a href="./files/slide_DPA_DenseBiasNet.pdf">&nbsp;Slide&nbsp;</a> |<a href="https://link.springer.com/chapter/10.1007/978-3-030-32226-7_16">&nbsp;MICCAI2019 version&nbsp;</a> |<a href="./files/bib_DPA_DenseBiasNet.txt">&nbsp;Bibtex&nbsp;</a></p>
                        </td></tr>
                        
                        <tr><td>
                        <p class="pub_title">Multi-Task Learning for Pulmonary Arterial Hypertension Prognosis Prediction via Memory Drift and Prior Prompt Learning on 3D Chest CT.</p>
                        <p class="pub_author">Guanyu Yang#, <u><b>Yuting He# (Equal contribution)</b></u>, Yang Lv, Yang Chen, Jean-Louis Coatrieux, Xiaoxuan Sun, Qiang Wang, Yongyue Wei, Shuo Li, and Yinsu Zhu.<br>
                        <i>IEEE Journal of Biomedical and Health Informatics</i><br>
                        <font color="#922B21"><b>&nbsp;IEEE J-BHI 2023&nbsp;</b></font> |<a href= "https://ieeexplore.ieee.org/document/10049641">&nbsp;Paper&nbsp;</a> |<a href="https://github.com/YutingHe-list/P2-Net">&nbsp;Code&nbsp;</a> |<a href="./files/slide_P2Net.pdf">&nbsp;Slide (Chinese)&nbsp;</a> |<a href="./files/bib_P2Net.txt">&nbsp;Bibtex&nbsp;</a></p>
                        </td></tr>
                        
                        <tr><td>
                        <p class="pub_title">EnMcGAN: Adversarial Ensemble Learning for 3D Complete Renal Structures Segmentation.</p>
                        <p class="pub_author"><u><b>Yuting He</b></u>, Rongjun Ge, Xiaoming Qi, Guanyu Yang, Yang Chen, Youyong Kong, Huazhong Shu, Jean-Louis Coatrieux, Shuo Li.<br>
                        <i>International Conference on Information Processing in Medical Imaging</i><br>
                        <font color="#922B21"><b>&nbsp;IPMI 2021&nbsp;</b></font> |<a href= "https://link.springer.com/chapter/10.1007/978-3-030-78191-0_36">&nbsp;Paper&nbsp;</a> |<a href="./files/poster_EnMcGAN.pdf">&nbsp;Poster&nbsp;</a> |<a href="./files/bib_EnMcGAN.txt">&nbsp;Bibtex&nbsp;</a></p>
                        </td></tr>
                        
                        <tr><td>
                        <p class="pub_title">CPNet: cycle prototype network for weakly-supervised 3D renal compartments segmentation on CT images.</p>
                        <p class="pub_author">Song Wang#, <u><b>Yuting He# (Equal contribution)</b></u>, Youyong Kong, Xiaomei Zhu, Shaobo Zhang, Pengfei Shao, Jean-Louis Dillenseger, Jean-Louis Coatrieux, Shuo Li, Guanyu Yang.<br>
                        <i>International Conference on Medical Image Computing and Computer-Assisted Intervention</i><br>
                        <font color="#922B21"><b>&nbsp;MICCAI 2021&nbsp;</b></font> |<a href= "https://link.springer.com/chapter/10.1007/978-3-030-87196-3_55">&nbsp;Paper&nbsp;</a> |<a href="./files/bib_CPNet.txt">&nbsp;Bibtex&nbsp;</a></p>
                        </td></tr>
                </table>
                
                <a id="services" class="anchor"></a>
                <h2>Services</h2>
                
                <p>Workshop/Challenge Organizers:</p>
                <ul>
                    <li>Co-organizer of <a href="https://kipa22.grand-challenge.org/">MICCAI-KiPA22</a> challenge.</li>
                </ul>
                
                <p>Conference Reviewer:</p>
                <ul>
                    <li>MICCAI, AAAI, CVPR, ICCV, NeurIPS.</li>
                </ul>
                
                <p>Journal Reviewer:</p>
                <ul>
                    <li>IEEE Transactions on Medical Imaging (TMI)</li>
                    <li>IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</li>
                    <li>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</li>
                    <li>IEEE Journal of Biomedical and Health Informatics (J-BHI)</li>
                    <li>Computerized Medical Imaging and Graphics (CMIG)</li>
                    <li>Machine Intelligence Research (MIR)</li>
                </ul>

        </div>
    </div>
</body>
</html>














